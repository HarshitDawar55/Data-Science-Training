{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 6 of Data Science Training by `Mr. Harshit Dawar`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Machine Learning\n",
    "* Supervised Learning:  Has always a class/label associated with it.\n",
    "  * Regression: It predicts a value on the continuous data.\n",
    "  * Classification: It classifies the data into various categories.\n",
    "  \n",
    "* Unsupervised Learning: No output class associated with data.\n",
    "  * Clustering: \n",
    "  \n",
    "* Reinforcement Learning: Agent interacts with the environment.\n",
    "\n",
    "* Transfer Learning: Use the base features of one model to train another one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss/Cost Function\n",
    "* It is a function which is used to minimize the error in model actual value vs predicted value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent  [Very Important Topic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(x, y, learning_rate):\n",
    "    # Equation of line = slope * x + intercept\n",
    "    slope = 0\n",
    "    intercept = 0\n",
    "    \n",
    "    for i in range(900):\n",
    "        # It will converge in both cases, as if slope is -ve then according to the loss function it will \n",
    "        # be added to provide desired result and if the slope is +ve then according to the loss function it \n",
    "        # will be subtracted to converge at the minimum point on the curve.\n",
    "        \n",
    "        loss_value = y - (slope * x + intercept)\n",
    "        \n",
    "        # Updating slope and intercept\n",
    "        slope = slope + learning_rate * np.sum(loss_value * x)\n",
    "        intercept = intercept + learning_rate * np.sum(loss_value)\n",
    "        \n",
    "    return slope, intercept\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, c = gradient_descent(np.arange(1,10,1), np.arange(5,14,1), learning_rate = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.1126386377466844, 3.2912485433198966)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (15, 7))\n",
    "plt.scatter(np.arange(1,10,1), np.arange(5,14,1))\n",
    "plt.plot(np.arange(1,10,1), m * np.arange(1,10,1) + c)\n",
    "plt.ylim(0, 15)\n",
    "plt.xlim(0,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent\n",
    "* Takes average for a smaller subpart of the data and applies nomal gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Works on gradient distance and uses `Euclidean Distance as a parameter to construct a line`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing machine learning library\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data PreProcessing for this project\n",
    "* Remove missing values.\n",
    "* Categorical features into numerical features.\n",
    "* Split the data into training and testing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset for required features\n",
    "data.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Fare\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch Cabin Embarked\n",
       "0           0       3    male  22.0      1      0   NaN        S\n",
       "1           1       1  female  38.0      1      0   C85        C\n",
       "2           1       3  female  26.0      0      0   NaN        S\n",
       "3           1       1  female  35.0      1      0  C123        S\n",
       "4           0       3    male  35.0      0      0   NaN        S\n",
       "..        ...     ...     ...   ...    ...    ...   ...      ...\n",
       "886         0       2    male  27.0      0      0   NaN        S\n",
       "887         1       1  female  19.0      0      0   B42        S\n",
       "888         0       3  female   NaN      1      2   NaN        S\n",
       "889         1       1    male  26.0      0      0  C148        C\n",
       "890         0       3    male  32.0      0      0   NaN        Q\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting data into labels and features\n",
    "X = data.drop(\"Survived\", axis = 1)\n",
    "y = data[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass     Sex   Age  SibSp  Parch Cabin Embarked\n",
       "0         3    male  22.0      1      0   NaN        S\n",
       "1         1  female  38.0      1      0   C85        C\n",
       "2         3  female  26.0      0      0   NaN        S\n",
       "3         1  female  35.0      1      0  C123        S\n",
       "4         3    male  35.0      0      0   NaN        S\n",
       "..      ...     ...   ...    ...    ...   ...      ...\n",
       "886       2    male  27.0      0      0   NaN        S\n",
       "887       1  female  19.0      0      0   B42        S\n",
       "888       3  female   NaN      1      2   NaN        S\n",
       "889       1    male  26.0      0      0  C148        C\n",
       "890       3    male  32.0      0      0   NaN        Q\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "      ..\n",
       "886    0\n",
       "887    1\n",
       "888    0\n",
       "889    1\n",
       "890    0\n",
       "Name: Survived, Length: 891, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        int64\n",
       "Sex          object\n",
       "Age         float64\n",
       "SibSp         int64\n",
       "Parch         int64\n",
       "Cabin        object\n",
       "Embarked     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values\n",
    "\n",
    "# For categorical\n",
    "categorical_features = [\"Cabin\", \"Embarked\"]\n",
    "\n",
    "si_categorical = SimpleImputer(strategy = \"constant\", fill_value = \"Missing\")\n",
    "\n",
    "# For Numerical\n",
    "\n",
    "numerical_features = [\"Age\"]\n",
    "\n",
    "si_numerical = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "#Transforming them\n",
    "\n",
    "transformer = ColumnTransformer(transformers=[\n",
    "                                (\"categorical_transformation\", si_categorical, categorical_features),\n",
    "                                (\"numerical_transformation\", si_numerical, numerical_features)],\n",
    "                                remainder = \"passthrough\"\n",
    ")\n",
    "\n",
    "X_transformed = transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = pd.DataFrame(X_transformed, columns = [\"Cabin\", \"Embarked\", \"Age\", \"Pclass\",\"Sex\", \"SibSp\", \"Parch\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin       0\n",
       "Embarked    0\n",
       "Age         0\n",
       "Pclass      0\n",
       "Sex         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Missing</td>\n",
       "      <td>S</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Missing</td>\n",
       "      <td>S</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Missing</td>\n",
       "      <td>S</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cabin Embarked Age Pclass     Sex SibSp Parch\n",
       "0  Missing        S  22      3    male     1     0\n",
       "1      C85        C  38      1  female     1     0\n",
       "2  Missing        S  26      3  female     0     0\n",
       "3     C123        S  35      1  female     1     0\n",
       "4  Missing        S  35      3    male     0     0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed[\"Cabin\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_transformed[\"Cabin\"])):\n",
    "    X_transformed[\"Cabin\"][i] = X_transformed[\"Cabin\"][i][: 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>S</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cabin Embarked Age Pclass     Sex SibSp Parch\n",
       "0     M        S  22      3    male     1     0\n",
       "1     C        C  38      1  female     1     0\n",
       "2     M        S  26      3  female     0     0\n",
       "3     C        S  35      1  female     1     0\n",
       "4     M        S  35      3    male     0     0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed[\"Cabin\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed[\"Embarked\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed[\"Sex\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin       object\n",
       "Embarked    object\n",
       "Age         object\n",
       "Pclass      object\n",
       "Sex         object\n",
       "SibSp       object\n",
       "Parch       object\n",
       "dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_transformed.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"Cabin\", \"Embarked\", \"Sex\"]\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown = \"ignore\")\n",
    "\n",
    "transformer2 = ColumnTransformer(transformers=[\n",
    "                                    (\"onehotencdoing\", encoder, features)],\n",
    "                                 remainder=\"passthrough\"\n",
    "                                )\n",
    "\n",
    "X_final = transformer2.fit_transform(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = pd.DataFrame(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.6991</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2  3  4  5  6  7  8  9 10 11 12 13 14       15 16 17 18\n",
       "0    0  0  0  0  0  0  0  1  0  0  0  0  1  0  1       22  3  1  0\n",
       "1    0  0  1  0  0  0  0  0  0  1  0  0  0  1  0       38  1  1  0\n",
       "2    0  0  0  0  0  0  0  1  0  0  0  0  1  1  0       26  3  0  0\n",
       "3    0  0  1  0  0  0  0  0  0  0  0  0  1  1  0       35  1  1  0\n",
       "4    0  0  0  0  0  0  0  1  0  0  0  0  1  0  1       35  3  0  0\n",
       "..  .. .. .. .. .. .. .. .. .. .. .. .. .. .. ..      ... .. .. ..\n",
       "886  0  0  0  0  0  0  0  1  0  0  0  0  1  0  1       27  2  0  0\n",
       "887  0  1  0  0  0  0  0  0  0  0  0  0  1  1  0       19  1  0  0\n",
       "888  0  0  0  0  0  0  0  1  0  0  0  0  1  1  0  29.6991  3  1  2\n",
       "889  0  0  1  0  0  0  0  0  0  1  0  0  0  0  1       26  1  0  0\n",
       "890  0  0  0  0  0  0  0  1  0  0  0  1  0  0  1       32  3  0  0\n",
       "\n",
       "[891 rows x 19 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           22\n",
       "1           38\n",
       "2           26\n",
       "3           35\n",
       "4           35\n",
       "        ...   \n",
       "886         27\n",
       "887         19\n",
       "888    29.6991\n",
       "889         26\n",
       "890         32\n",
       "Name: 15, Length: 891, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating object for it\n",
    "classifier = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[22.         38.         26.         35.         35.         29.69911765\n 54.          2.         27.         14.          4.         58.\n 20.         39.         14.         55.          2.         29.69911765\n 31.         29.69911765 35.         34.         15.         28.\n  8.         38.         29.69911765 19.         29.69911765 29.69911765\n 40.         29.69911765 29.69911765 66.         28.         42.\n 29.69911765 21.         18.         14.         40.         27.\n 29.69911765  3.         19.         29.69911765 29.69911765 29.69911765\n 29.69911765 18.          7.         21.         49.         29.\n 65.         29.69911765 21.         28.5         5.         11.\n 22.         38.         45.          4.         29.69911765 29.69911765\n 29.         19.         17.         26.         32.         16.\n 21.         26.         32.         25.         29.69911765 29.69911765\n  0.83       30.         22.         29.         29.69911765 28.\n 17.         33.         16.         29.69911765 23.         24.\n 29.         20.         46.         26.         59.         29.69911765\n 71.         23.         34.         34.         28.         29.69911765\n 21.         33.         37.         28.         21.         29.69911765\n 38.         29.69911765 47.         14.5        22.         20.\n 17.         21.         70.5        29.         24.          2.\n 21.         29.69911765 32.5        32.5        54.         12.\n 29.69911765 24.         29.69911765 45.         33.         20.\n 47.         29.         25.         23.         19.         37.\n 16.         24.         29.69911765 22.         24.         19.\n 18.         19.         27.          9.         36.5        42.\n 51.         22.         55.5        40.5        29.69911765 51.\n 16.         30.         29.69911765 29.69911765 44.         40.\n 26.         17.          1.          9.         29.69911765 45.\n 29.69911765 28.         61.          4.          1.         21.\n 56.         18.         29.69911765 50.         30.         36.\n 29.69911765 29.69911765  9.          1.          4.         29.69911765\n 29.69911765 45.         40.         36.         32.         19.\n 19.          3.         44.         58.         29.69911765 42.\n 29.69911765 24.         28.         29.69911765 34.         45.5\n 18.          2.         32.         26.         16.         40.\n 24.         35.         22.         30.         29.69911765 31.\n 27.         42.         32.         30.         16.         27.\n 51.         29.69911765 38.         22.         19.         20.5\n 18.         29.69911765 35.         29.         59.          5.\n 24.         29.69911765 44.          8.         19.         33.\n 29.69911765 29.69911765 29.         22.         30.         44.\n 25.         24.         37.         54.         29.69911765 29.\n 62.         30.         41.         29.         29.69911765 30.\n 35.         50.         29.69911765  3.         52.         40.\n 29.69911765 36.         16.         25.         58.         35.\n 29.69911765 25.         41.         37.         29.69911765 63.\n 45.         29.69911765  7.         35.         65.         28.\n 16.         19.         29.69911765 33.         30.         22.\n 42.         22.         26.         19.         36.         24.\n 24.         29.69911765 23.5         2.         29.69911765 50.\n 29.69911765 29.69911765 19.         29.69911765 29.69911765  0.92\n 29.69911765 17.         30.         30.         24.         18.\n 26.         28.         43.         26.         24.         54.\n 31.         40.         22.         27.         30.         22.\n 29.69911765 36.         61.         36.         31.         16.\n 29.69911765 45.5        38.         16.         29.69911765 29.69911765\n 29.         41.         45.         45.          2.         24.\n 28.         25.         36.         24.         40.         29.69911765\n  3.         42.         23.         29.69911765 15.         25.\n 29.69911765 28.         22.         38.         29.69911765 29.69911765\n 40.         29.         45.         35.         29.69911765 30.\n 60.         29.69911765 29.69911765 24.         25.         18.\n 19.         22.          3.         29.69911765 22.         27.\n 20.         19.         42.          1.         32.         35.\n 29.69911765 18.          1.         36.         29.69911765 17.\n 36.         21.         28.         23.         24.         22.\n 31.         46.         23.         28.         39.         26.\n 21.         28.         20.         34.         51.          3.\n 21.         29.69911765 29.69911765 29.69911765 33.         29.69911765\n 44.         29.69911765 34.         18.         30.         10.\n 29.69911765 21.         29.         28.         18.         29.69911765\n 28.         19.         29.69911765 32.         28.         29.69911765\n 42.         17.         50.         14.         21.         24.\n 64.         31.         45.         20.         25.         28.\n 29.69911765  4.         13.         34.          5.         52.\n 36.         29.69911765 30.         49.         29.69911765 29.\n 65.         29.69911765 50.         29.69911765 48.         34.\n 47.         48.         29.69911765 38.         29.69911765 56.\n 29.69911765  0.75       29.69911765 38.         33.         23.\n 22.         29.69911765 34.         29.         22.          2.\n  9.         29.69911765 50.         63.         25.         29.69911765\n 35.         58.         30.          9.         29.69911765 21.\n 55.         71.         21.         29.69911765 54.         29.69911765\n 25.         24.         17.         21.         29.69911765 37.\n 16.         18.         33.         29.69911765 28.         26.\n 29.         29.69911765 36.         54.         24.         47.\n 34.         29.69911765 36.         32.         30.         22.\n 29.69911765 44.         29.69911765 40.5        50.         29.69911765\n 39.         23.          2.         29.69911765 17.         29.69911765\n 30.          7.         45.         30.         29.69911765 22.\n 36.          9.         11.         32.         50.         64.\n 19.         29.69911765 33.          8.         17.         27.\n 29.69911765 22.         22.         62.         48.         29.69911765\n 39.         36.         29.69911765 40.         28.         29.69911765\n 29.69911765 24.         19.         29.         29.69911765 32.\n 62.         53.         36.         29.69911765 16.         19.\n 34.         39.         29.69911765 32.         25.         39.\n 54.         36.         29.69911765 18.         47.         60.\n 22.         29.69911765 35.         52.         47.         29.69911765\n 37.         36.         29.69911765 49.         29.69911765 49.\n 24.         29.69911765 29.69911765 44.         35.         36.\n 30.         27.         22.         40.         39.         29.69911765\n 29.69911765 29.69911765 35.         24.         34.         26.\n  4.         26.         27.         42.         20.         21.\n 21.         61.         57.         21.         26.         29.69911765\n 80.         51.         32.         29.69911765  9.         28.\n 32.         31.         41.         29.69911765 20.         24.\n  2.         29.69911765  0.75       48.         19.         56.\n 29.69911765 23.         29.69911765 18.         21.         29.69911765\n 18.         24.         29.69911765 32.         23.         58.\n 50.         40.         47.         36.         20.         32.\n 25.         29.69911765 43.         29.69911765 40.         31.\n 70.         31.         29.69911765 18.         24.5        18.\n 43.         36.         29.69911765 27.         20.         14.\n 60.         25.         14.         19.         18.         15.\n 31.          4.         29.69911765 25.         60.         52.\n 44.         29.69911765 49.         42.         18.         35.\n 18.         25.         26.         39.         45.         42.\n 22.         29.69911765 24.         29.69911765 48.         29.\n 52.         19.         38.         27.         29.69911765 33.\n  6.         17.         34.         50.         27.         20.\n 30.         29.69911765 25.         25.         29.         11.\n 29.69911765 23.         23.         28.5        48.         35.\n 29.69911765 29.69911765 29.69911765 36.         21.         24.\n 31.         70.         16.         30.         19.         31.\n  4.          6.         33.         23.         48.          0.67\n 28.         18.         34.         33.         29.69911765 41.\n 20.         36.         16.         51.         29.69911765 30.5\n 29.69911765 32.         24.         48.         57.         29.69911765\n 54.         18.         29.69911765  5.         29.69911765 43.\n 13.         17.         29.         29.69911765 25.         25.\n 18.          8.          1.         46.         29.69911765 16.\n 29.69911765 29.69911765 25.         39.         49.         31.\n 30.         30.         34.         31.         11.          0.42\n 27.         31.         39.         18.         39.         33.\n 26.         39.         35.          6.         30.5        29.69911765\n 23.         31.         43.         10.         52.         27.\n 38.         27.          2.         29.69911765 29.69911765  1.\n 29.69911765 62.         15.          0.83       29.69911765 23.\n 18.         39.         21.         29.69911765 32.         29.69911765\n 20.         16.         30.         34.5        17.         42.\n 29.69911765 35.         28.         29.69911765  4.         74.\n  9.         16.         44.         18.         45.         51.\n 24.         29.69911765 41.         21.         48.         29.69911765\n 24.         42.         27.         31.         29.69911765  4.\n 26.         47.         33.         47.         28.         15.\n 20.         19.         29.69911765 56.         25.         33.\n 22.         28.         25.         39.         27.         19.\n 29.69911765 26.         32.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-e3bf753607a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fitiing the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_final\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/DataScieneTraining/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0m\u001b[1;32m    492\u001b[0m                          y_numeric=True, multi_output=True)\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DataScieneTraining/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    748\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/DataScieneTraining/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    553\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[22.         38.         26.         35.         35.         29.69911765\n 54.          2.         27.         14.          4.         58.\n 20.         39.         14.         55.          2.         29.69911765\n 31.         29.69911765 35.         34.         15.         28.\n  8.         38.         29.69911765 19.         29.69911765 29.69911765\n 40.         29.69911765 29.69911765 66.         28.         42.\n 29.69911765 21.         18.         14.         40.         27.\n 29.69911765  3.         19.         29.69911765 29.69911765 29.69911765\n 29.69911765 18.          7.         21.         49.         29.\n 65.         29.69911765 21.         28.5         5.         11.\n 22.         38.         45.          4.         29.69911765 29.69911765\n 29.         19.         17.         26.         32.         16.\n 21.         26.         32.         25.         29.69911765 29.69911765\n  0.83       30.         22.         29.         29.69911765 28.\n 17.         33.         16.         29.69911765 23.         24.\n 29.         20.         46.         26.         59.         29.69911765\n 71.         23.         34.         34.         28.         29.69911765\n 21.         33.         37.         28.         21.         29.69911765\n 38.         29.69911765 47.         14.5        22.         20.\n 17.         21.         70.5        29.         24.          2.\n 21.         29.69911765 32.5        32.5        54.         12.\n 29.69911765 24.         29.69911765 45.         33.         20.\n 47.         29.         25.         23.         19.         37.\n 16.         24.         29.69911765 22.         24.         19.\n 18.         19.         27.          9.         36.5        42.\n 51.         22.         55.5        40.5        29.69911765 51.\n 16.         30.         29.69911765 29.69911765 44.         40.\n 26.         17.          1.          9.         29.69911765 45.\n 29.69911765 28.         61.          4.          1.         21.\n 56.         18.         29.69911765 50.         30.         36.\n 29.69911765 29.69911765  9.          1.          4.         29.69911765\n 29.69911765 45.         40.         36.         32.         19.\n 19.          3.         44.         58.         29.69911765 42.\n 29.69911765 24.         28.         29.69911765 34.         45.5\n 18.          2.         32.         26.         16.         40.\n 24.         35.         22.         30.         29.69911765 31.\n 27.         42.         32.         30.         16.         27.\n 51.         29.69911765 38.         22.         19.         20.5\n 18.         29.69911765 35.         29.         59.          5.\n 24.         29.69911765 44.          8.         19.         33.\n 29.69911765 29.69911765 29.         22.         30.         44.\n 25.         24.         37.         54.         29.69911765 29.\n 62.         30.         41.         29.         29.69911765 30.\n 35.         50.         29.69911765  3.         52.         40.\n 29.69911765 36.         16.         25.         58.         35.\n 29.69911765 25.         41.         37.         29.69911765 63.\n 45.         29.69911765  7.         35.         65.         28.\n 16.         19.         29.69911765 33.         30.         22.\n 42.         22.         26.         19.         36.         24.\n 24.         29.69911765 23.5         2.         29.69911765 50.\n 29.69911765 29.69911765 19.         29.69911765 29.69911765  0.92\n 29.69911765 17.         30.         30.         24.         18.\n 26.         28.         43.         26.         24.         54.\n 31.         40.         22.         27.         30.         22.\n 29.69911765 36.         61.         36.         31.         16.\n 29.69911765 45.5        38.         16.         29.69911765 29.69911765\n 29.         41.         45.         45.          2.         24.\n 28.         25.         36.         24.         40.         29.69911765\n  3.         42.         23.         29.69911765 15.         25.\n 29.69911765 28.         22.         38.         29.69911765 29.69911765\n 40.         29.         45.         35.         29.69911765 30.\n 60.         29.69911765 29.69911765 24.         25.         18.\n 19.         22.          3.         29.69911765 22.         27.\n 20.         19.         42.          1.         32.         35.\n 29.69911765 18.          1.         36.         29.69911765 17.\n 36.         21.         28.         23.         24.         22.\n 31.         46.         23.         28.         39.         26.\n 21.         28.         20.         34.         51.          3.\n 21.         29.69911765 29.69911765 29.69911765 33.         29.69911765\n 44.         29.69911765 34.         18.         30.         10.\n 29.69911765 21.         29.         28.         18.         29.69911765\n 28.         19.         29.69911765 32.         28.         29.69911765\n 42.         17.         50.         14.         21.         24.\n 64.         31.         45.         20.         25.         28.\n 29.69911765  4.         13.         34.          5.         52.\n 36.         29.69911765 30.         49.         29.69911765 29.\n 65.         29.69911765 50.         29.69911765 48.         34.\n 47.         48.         29.69911765 38.         29.69911765 56.\n 29.69911765  0.75       29.69911765 38.         33.         23.\n 22.         29.69911765 34.         29.         22.          2.\n  9.         29.69911765 50.         63.         25.         29.69911765\n 35.         58.         30.          9.         29.69911765 21.\n 55.         71.         21.         29.69911765 54.         29.69911765\n 25.         24.         17.         21.         29.69911765 37.\n 16.         18.         33.         29.69911765 28.         26.\n 29.         29.69911765 36.         54.         24.         47.\n 34.         29.69911765 36.         32.         30.         22.\n 29.69911765 44.         29.69911765 40.5        50.         29.69911765\n 39.         23.          2.         29.69911765 17.         29.69911765\n 30.          7.         45.         30.         29.69911765 22.\n 36.          9.         11.         32.         50.         64.\n 19.         29.69911765 33.          8.         17.         27.\n 29.69911765 22.         22.         62.         48.         29.69911765\n 39.         36.         29.69911765 40.         28.         29.69911765\n 29.69911765 24.         19.         29.         29.69911765 32.\n 62.         53.         36.         29.69911765 16.         19.\n 34.         39.         29.69911765 32.         25.         39.\n 54.         36.         29.69911765 18.         47.         60.\n 22.         29.69911765 35.         52.         47.         29.69911765\n 37.         36.         29.69911765 49.         29.69911765 49.\n 24.         29.69911765 29.69911765 44.         35.         36.\n 30.         27.         22.         40.         39.         29.69911765\n 29.69911765 29.69911765 35.         24.         34.         26.\n  4.         26.         27.         42.         20.         21.\n 21.         61.         57.         21.         26.         29.69911765\n 80.         51.         32.         29.69911765  9.         28.\n 32.         31.         41.         29.69911765 20.         24.\n  2.         29.69911765  0.75       48.         19.         56.\n 29.69911765 23.         29.69911765 18.         21.         29.69911765\n 18.         24.         29.69911765 32.         23.         58.\n 50.         40.         47.         36.         20.         32.\n 25.         29.69911765 43.         29.69911765 40.         31.\n 70.         31.         29.69911765 18.         24.5        18.\n 43.         36.         29.69911765 27.         20.         14.\n 60.         25.         14.         19.         18.         15.\n 31.          4.         29.69911765 25.         60.         52.\n 44.         29.69911765 49.         42.         18.         35.\n 18.         25.         26.         39.         45.         42.\n 22.         29.69911765 24.         29.69911765 48.         29.\n 52.         19.         38.         27.         29.69911765 33.\n  6.         17.         34.         50.         27.         20.\n 30.         29.69911765 25.         25.         29.         11.\n 29.69911765 23.         23.         28.5        48.         35.\n 29.69911765 29.69911765 29.69911765 36.         21.         24.\n 31.         70.         16.         30.         19.         31.\n  4.          6.         33.         23.         48.          0.67\n 28.         18.         34.         33.         29.69911765 41.\n 20.         36.         16.         51.         29.69911765 30.5\n 29.69911765 32.         24.         48.         57.         29.69911765\n 54.         18.         29.69911765  5.         29.69911765 43.\n 13.         17.         29.         29.69911765 25.         25.\n 18.          8.          1.         46.         29.69911765 16.\n 29.69911765 29.69911765 25.         39.         49.         31.\n 30.         30.         34.         31.         11.          0.42\n 27.         31.         39.         18.         39.         33.\n 26.         39.         35.          6.         30.5        29.69911765\n 23.         31.         43.         10.         52.         27.\n 38.         27.          2.         29.69911765 29.69911765  1.\n 29.69911765 62.         15.          0.83       29.69911765 23.\n 18.         39.         21.         29.69911765 32.         29.69911765\n 20.         16.         30.         34.5        17.         42.\n 29.69911765 35.         28.         29.69911765  4.         74.\n  9.         16.         44.         18.         45.         51.\n 24.         29.69911765 41.         21.         48.         29.69911765\n 24.         42.         27.         31.         29.69911765  4.\n 26.         47.         33.         47.         28.         15.\n 20.         19.         29.69911765 56.         25.         33.\n 22.         28.         25.         39.         27.         19.\n 29.69911765 26.         32.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Fitiing the dataset without reshaping => error\n",
    "classifier.fit(X_final[15], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final[15].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the array to fit the model.\n",
    "\n",
    "t = np.array(X_final[15]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(t, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting data into training & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_final, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 19), (179, 19), (712,), (179,))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier2.fit(np.array(x_train).reshape(-1, 1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting\n",
    "y_pred = classifier2.predict(np.array(x_test).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.12"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round((accuracy_score(y_test, y_pred) * 100), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.12"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round((clf.score(x_test, y_test)* 100), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "..  ..\n",
       "174  1\n",
       "175  0\n",
       "176  0\n",
       "177  0\n",
       "178  1\n",
       "\n",
       "[179 rows x 1 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.to_csv(\"Predicted_Titanic.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hope you understood well and many topics are covered!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
